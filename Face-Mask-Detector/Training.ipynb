{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98be179d",
   "metadata": {},
   "source": [
    "# Install the packages using the following commands :\n",
    "\n",
    "    pip3 install tensorflow    \n",
    "    pip3 install opencv-python\n",
    "    pip3 install sklearn scikit-learn auto-sklearn\n",
    "    pip3 install pygame imutils\n",
    "    pip3 install numpy matplotlib \n",
    "    pip3 install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1878e7",
   "metadata": {},
   "source": [
    "# Import all necessary packages to train the Face Mask Detector Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeb0daa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281ab3be",
   "metadata": {},
   "source": [
    "# Initialize the initial learning rate, number of epochs to train and batch size \n",
    "\n",
    "   Also allocate the directory of the folder containg the datasets .\n",
    "   \n",
    "   grab the list of images in our dataset directory, then initialize the list of data (i.e., images) and class images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d0e9c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reddy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\PIL\\Image.py:973: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "INIT_LR = 1e-4\n",
    "EPOCHS = 75\n",
    "BS = 32\n",
    "\n",
    "DIRECTORY = r\"dataset\"\n",
    "CATEGORIES = [\"with_mask\", \"without_mask\"]\n",
    "\n",
    "print(\"[INFO] loading images...\")\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DIRECTORY, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        image = load_img(img_path, target_size=(224, 224))\n",
    "        image = img_to_array(image)\n",
    "        image = preprocess_input(image)\n",
    "\n",
    "        data.append(image)\n",
    "        labels.append(category)\n",
    "        \n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.20, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e0cfd2",
   "metadata": {},
   "source": [
    "# construct the training image generator for data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8252c5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dc6f4f",
   "metadata": {},
   "source": [
    "# load the MobileNetV2 network, ensuring the head FC layer sets are left off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dd5f544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "#construct the head of the model that will be placed on top of the base model\n",
    "\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
    "\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "#loop over all layers in the base model and freeze them so they will *not* be updated during the first training process\n",
    "\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31886fe2",
   "metadata": {},
   "source": [
    "# compile our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6840ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reddy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8009201",
   "metadata": {},
   "source": [
    "# train the head of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bb228d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training head...\n",
      "Epoch 1/75\n",
      "184/184 [==============================] - ETA: 0s - loss: 0.2362 - accuracy: 0.9195WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 46 batches). You may need to use the repeat() function when building your dataset.\n",
      "184/184 [==============================] - 156s 842ms/step - loss: 0.2362 - accuracy: 0.9195 - val_loss: 0.0860 - val_accuracy: 0.9736\n",
      "Epoch 2/75\n",
      "184/184 [==============================] - 148s 804ms/step - loss: 0.0829 - accuracy: 0.9770\n",
      "Epoch 3/75\n",
      "184/184 [==============================] - 122s 660ms/step - loss: 0.0690 - accuracy: 0.9809\n",
      "Epoch 4/75\n",
      "184/184 [==============================] - 119s 646ms/step - loss: 0.0620 - accuracy: 0.9813\n",
      "Epoch 5/75\n",
      "184/184 [==============================] - 125s 677ms/step - loss: 0.0575 - accuracy: 0.9842\n",
      "Epoch 6/75\n",
      "184/184 [==============================] - 125s 678ms/step - loss: 0.0540 - accuracy: 0.9860\n",
      "Epoch 7/75\n",
      "184/184 [==============================] - 126s 685ms/step - loss: 0.0458 - accuracy: 0.9867\n",
      "Epoch 8/75\n",
      "184/184 [==============================] - 124s 673ms/step - loss: 0.0473 - accuracy: 0.9860\n",
      "Epoch 9/75\n",
      "184/184 [==============================] - 121s 656ms/step - loss: 0.0439 - accuracy: 0.9871\n",
      "Epoch 10/75\n",
      "184/184 [==============================] - 127s 691ms/step - loss: 0.0441 - accuracy: 0.9871\n",
      "Epoch 11/75\n",
      "184/184 [==============================] - 124s 672ms/step - loss: 0.0431 - accuracy: 0.9871\n",
      "Epoch 12/75\n",
      "184/184 [==============================] - 123s 667ms/step - loss: 0.0424 - accuracy: 0.9862\n",
      "Epoch 13/75\n",
      "184/184 [==============================] - 122s 664ms/step - loss: 0.0441 - accuracy: 0.9864\n",
      "Epoch 14/75\n",
      "184/184 [==============================] - 115s 622ms/step - loss: 0.0401 - accuracy: 0.9891\n",
      "Epoch 15/75\n",
      "184/184 [==============================] - 120s 650ms/step - loss: 0.0382 - accuracy: 0.9867\n",
      "Epoch 16/75\n",
      "184/184 [==============================] - 113s 612ms/step - loss: 0.0375 - accuracy: 0.9872\n",
      "Epoch 17/75\n",
      "184/184 [==============================] - 110s 595ms/step - loss: 0.0354 - accuracy: 0.9891\n",
      "Epoch 18/75\n",
      "184/184 [==============================] - 113s 615ms/step - loss: 0.0372 - accuracy: 0.9881\n",
      "Epoch 19/75\n",
      "184/184 [==============================] - 118s 640ms/step - loss: 0.0305 - accuracy: 0.9910\n",
      "Epoch 20/75\n",
      "184/184 [==============================] - 121s 659ms/step - loss: 0.0337 - accuracy: 0.9898\n",
      "Epoch 21/75\n",
      "184/184 [==============================] - 119s 648ms/step - loss: 0.0328 - accuracy: 0.9896\n",
      "Epoch 22/75\n",
      "184/184 [==============================] - 113s 614ms/step - loss: 0.0340 - accuracy: 0.9896\n",
      "Epoch 23/75\n",
      "184/184 [==============================] - 117s 634ms/step - loss: 0.0299 - accuracy: 0.9881\n",
      "Epoch 24/75\n",
      "184/184 [==============================] - 120s 652ms/step - loss: 0.0319 - accuracy: 0.9903\n",
      "Epoch 25/75\n",
      "184/184 [==============================] - 112s 606ms/step - loss: 0.0312 - accuracy: 0.9891\n",
      "Epoch 26/75\n",
      "184/184 [==============================] - 114s 617ms/step - loss: 0.0318 - accuracy: 0.9903\n",
      "Epoch 27/75\n",
      "184/184 [==============================] - 116s 631ms/step - loss: 0.0261 - accuracy: 0.9912\n",
      "Epoch 28/75\n",
      "184/184 [==============================] - 120s 652ms/step - loss: 0.0256 - accuracy: 0.9913\n",
      "Epoch 29/75\n",
      "184/184 [==============================] - 110s 597ms/step - loss: 0.0276 - accuracy: 0.9908\n",
      "Epoch 30/75\n",
      "184/184 [==============================] - 114s 617ms/step - loss: 0.0277 - accuracy: 0.9906\n",
      "Epoch 31/75\n",
      "184/184 [==============================] - 116s 632ms/step - loss: 0.0257 - accuracy: 0.9898\n",
      "Epoch 32/75\n",
      "184/184 [==============================] - 121s 658ms/step - loss: 0.0260 - accuracy: 0.9908\n",
      "Epoch 33/75\n",
      "184/184 [==============================] - 114s 618ms/step - loss: 0.0287 - accuracy: 0.9901\n",
      "Epoch 34/75\n",
      "184/184 [==============================] - 114s 619ms/step - loss: 0.0231 - accuracy: 0.9918\n",
      "Epoch 35/75\n",
      "184/184 [==============================] - 118s 640ms/step - loss: 0.0250 - accuracy: 0.9918\n",
      "Epoch 36/75\n",
      "184/184 [==============================] - 118s 639ms/step - loss: 0.0268 - accuracy: 0.9903\n",
      "Epoch 37/75\n",
      "184/184 [==============================] - 111s 602ms/step - loss: 0.0250 - accuracy: 0.9906\n",
      "Epoch 38/75\n",
      "184/184 [==============================] - 114s 619ms/step - loss: 0.0264 - accuracy: 0.9918\n",
      "Epoch 39/75\n",
      "184/184 [==============================] - 117s 637ms/step - loss: 0.0223 - accuracy: 0.9925\n",
      "Epoch 40/75\n",
      "184/184 [==============================] - 117s 636ms/step - loss: 0.0233 - accuracy: 0.9908\n",
      "Epoch 41/75\n",
      "184/184 [==============================] - 112s 609ms/step - loss: 0.0212 - accuracy: 0.9923\n",
      "Epoch 42/75\n",
      "184/184 [==============================] - 115s 625ms/step - loss: 0.0207 - accuracy: 0.9918\n",
      "Epoch 43/75\n",
      "184/184 [==============================] - 119s 644ms/step - loss: 0.0250 - accuracy: 0.9910\n",
      "Epoch 44/75\n",
      "184/184 [==============================] - 122s 662ms/step - loss: 0.0243 - accuracy: 0.9910\n",
      "Epoch 45/75\n",
      "184/184 [==============================] - 111s 605ms/step - loss: 0.0210 - accuracy: 0.9929\n",
      "Epoch 46/75\n",
      "184/184 [==============================] - 115s 627ms/step - loss: 0.0220 - accuracy: 0.9908\n",
      "Epoch 47/75\n",
      "184/184 [==============================] - 118s 639ms/step - loss: 0.0209 - accuracy: 0.9918\n",
      "Epoch 48/75\n",
      "184/184 [==============================] - 111s 605ms/step - loss: 0.0184 - accuracy: 0.9937\n",
      "Epoch 49/75\n",
      "184/184 [==============================] - 112s 608ms/step - loss: 0.0228 - accuracy: 0.9915\n",
      "Epoch 50/75\n",
      "184/184 [==============================] - 115s 625ms/step - loss: 0.0216 - accuracy: 0.9927\n",
      "Epoch 51/75\n",
      "184/184 [==============================] - 119s 645ms/step - loss: 0.0178 - accuracy: 0.9922\n",
      "Epoch 52/75\n",
      "184/184 [==============================] - 109s 593ms/step - loss: 0.0200 - accuracy: 0.9930\n",
      "Epoch 53/75\n",
      "184/184 [==============================] - 111s 605ms/step - loss: 0.0229 - accuracy: 0.9915\n",
      "Epoch 54/75\n",
      "184/184 [==============================] - 115s 623ms/step - loss: 0.0162 - accuracy: 0.9940\n",
      "Epoch 55/75\n",
      "184/184 [==============================] - 106s 577ms/step - loss: 0.0193 - accuracy: 0.9932\n",
      "Epoch 56/75\n",
      "184/184 [==============================] - 110s 599ms/step - loss: 0.0189 - accuracy: 0.9944\n",
      "Epoch 57/75\n",
      "184/184 [==============================] - 112s 608ms/step - loss: 0.0178 - accuracy: 0.9925\n",
      "Epoch 58/75\n",
      "184/184 [==============================] - 116s 629ms/step - loss: 0.0189 - accuracy: 0.9934\n",
      "Epoch 59/75\n",
      "184/184 [==============================] - 112s 608ms/step - loss: 0.0177 - accuracy: 0.9927\n",
      "Epoch 60/75\n",
      "184/184 [==============================] - 109s 593ms/step - loss: 0.0178 - accuracy: 0.9935\n",
      "Epoch 61/75\n",
      "184/184 [==============================] - 112s 607ms/step - loss: 0.0172 - accuracy: 0.9942\n",
      "Epoch 62/75\n",
      "184/184 [==============================] - 116s 627ms/step - loss: 0.0162 - accuracy: 0.9942\n",
      "Epoch 63/75\n",
      "184/184 [==============================] - 112s 609ms/step - loss: 0.0164 - accuracy: 0.9940\n",
      "Epoch 64/75\n",
      "184/184 [==============================] - 109s 593ms/step - loss: 0.0201 - accuracy: 0.9923\n",
      "Epoch 65/75\n",
      "184/184 [==============================] - 119s 644ms/step - loss: 0.0180 - accuracy: 0.9930\n",
      "Epoch 66/75\n",
      "184/184 [==============================] - 133s 724ms/step - loss: 0.0172 - accuracy: 0.9934\n",
      "Epoch 67/75\n",
      "184/184 [==============================] - 125s 681ms/step - loss: 0.0150 - accuracy: 0.9946\n",
      "Epoch 68/75\n",
      "184/184 [==============================] - 121s 658ms/step - loss: 0.0159 - accuracy: 0.9942\n",
      "Epoch 69/75\n",
      "184/184 [==============================] - 121s 658ms/step - loss: 0.0144 - accuracy: 0.9949\n",
      "Epoch 70/75\n",
      "184/184 [==============================] - 121s 656ms/step - loss: 0.0137 - accuracy: 0.9954\n",
      "Epoch 71/75\n",
      "184/184 [==============================] - 118s 639ms/step - loss: 0.0168 - accuracy: 0.9946\n",
      "Epoch 72/75\n",
      "184/184 [==============================] - 103s 558ms/step - loss: 0.0149 - accuracy: 0.9942\n",
      "Epoch 73/75\n",
      "184/184 [==============================] - 104s 564ms/step - loss: 0.0143 - accuracy: 0.9951\n",
      "Epoch 74/75\n",
      "184/184 [==============================] - 106s 575ms/step - loss: 0.0155 - accuracy: 0.9946\n",
      "Epoch 75/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 108s 586ms/step - loss: 0.0181 - accuracy: 0.9934\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   with_mask       0.98      1.00      0.99       709\n",
      "without_mask       1.00      0.98      0.99       769\n",
      "\n",
      "    accuracy                           0.99      1478\n",
      "   macro avg       0.99      0.99      0.99      1478\n",
      "weighted avg       0.99      0.99      0.99      1478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training head...\")\n",
    "H = model.fit(\n",
    "    aug.flow(trainX, trainY, batch_size=BS),\n",
    "    steps_per_epoch=len(trainX) // BS,\n",
    "    validation_data=(testX, testY),\n",
    "    validation_steps=len(testX) // BS,\n",
    "    epochs=EPOCHS)\n",
    "\n",
    "# make predictions on the testing set\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predIdxs = model.predict(testX, batch_size=BS)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(testY.argmax(axis=1), predIdxs, target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c50d11",
   "metadata": {},
   "source": [
    "# serialize the model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71a455f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving mask detector model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reddy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (75,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16600/1286975015.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train_acc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"val_acc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3017\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3018\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3019\u001b[1;33m     return gca().plot(\n\u001b[0m\u001b[0;32m   3020\u001b[0m         \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3021\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1603\u001b[0m         \"\"\"\n\u001b[0;32m   1604\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1605\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    313\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 501\u001b[1;33m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[0;32m    502\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[0;32m    503\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (75,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"[INFO] saving mask detector model...\")\n",
    "model.save(\"mask_detector.model\", save_format=\"h5\")\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "\n",
    "N = EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
